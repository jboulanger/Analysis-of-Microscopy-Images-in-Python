{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Loading data\n",
    "\n",
    "Image data acquired in microscopy are stored in various formats: TIF, LSM, CZI, LIF, ND2\n",
    "We'll use the imageanalysis kernel we have created earlier and we assume here that we are working in the example folder ( use %cd in the notebook to change directory ).\n",
    "\n",
    "Some image reader will return a numpy array which represents array of values on a regular grid. Other might return a Pillow object representing an image object. We may need to convert the multi-frame/slice/channel dataset into a multi-dimensional array (see LIF files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this cell we'll download and unzip the example data set\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def download_and_unzip(url, extract_to='.'):\n",
    "    http_response = urlopen(url)\n",
    "    zipfile = ZipFile(BytesIO(http_response.read()))\n",
    "    zipfile.extractall(path=extract_to)\n",
    "\n",
    "url = 'https://cloud.mrc-lmb.cam.ac.uk/s/crKayCH6YfTGccq/download'\n",
    "\n",
    "download_and_unzip(url, '../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loading TIF\n",
    "For loading TIF images, we can use the module tifffile. It also supports LSM (Zeiss), OME-TIF, ImageJ hyperstacks, etc.\n",
    "If installing modules manually, type in the prompt the command: \n",
    "```bash\n",
    "conda install tifffile\n",
    "```\n",
    "Let's load the all content of the file into a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We first load in python useful modules for loading and displaying images\r\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "# Let's set the name of the file we want to open\n",
    "filename = '../data/example.tif'\n",
    "\n",
    "# We use the tifffile module to read the image from disk\n",
    "img = tifffile.imread(filename)\n",
    "\n",
    "# Let's check the shape/size of the image (note the order of the planes)\n",
    "print(\"The shape of the array is [depth x channels x height x width]\", img.shape)\n",
    "\n",
    "# We select the middle plane and the second channel (indices starts at 0)\n",
    "middle_plane_index = round(img.shape[1] / 2)\n",
    "plane = img[middle_plane_index,1,:,:]\n",
    "plt.imshow(plane)\n",
    "plt.title('Channel:{ch} Plane:{z}'.format(ch=1,z=middle_plane_index))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Nikon ND2 files\n",
    "Nikon ND2 files can be loaded using the python module nd2reader (https://rbnvrw.github.io/nd2reader/). The module is available on the channel conda-forge. Add the conda-forge channel using the following command:\n",
    "```bash\n",
    "conda config --add channels conda-forge\n",
    "```\n",
    "and install it with:\n",
    "```\n",
    "conda install nd2reader\n",
    "```\n",
    "Now we can read an image from ND2 files using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We load first the nd2reader module\n",
    "from nd2reader import ND2Reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We are creating a reader for the nd2 image\n",
    "with ND2Reader('../data/example.nd2') as images:\n",
    "  \n",
    "  # Let's print out the image size\n",
    "  print('Image size:', images.sizes)\n",
    "  \n",
    "  # We define the axis on which we iterate the 2D planes\n",
    "  images.iter_axes = 'c'\n",
    "\n",
    "  # Let finally show the 2nd channel of the image\n",
    "  plt.imshow(images[1])\n",
    "  plt.title('A ND2 image')\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Leica LIF files\n",
    "For Leila LIF files we can use readlif https://pypi.org/project/readlif/ . This module needs to be installed using pip instead of conda using \n",
    "```\n",
    "pip install readlif\n",
    "```\n",
    "We use the function get_frame from readlif to get a Pillow 2D image.  \n",
    "Now let's read a LIF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's load the reader from the readlif module\n",
    "from readlif.reader import LifFile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# We create an object containing the image data\n",
    "filename = '../data/test.lif'\n",
    "lif = LifFile(filename)\n",
    "\n",
    "# Let count the number of data sets in the file\n",
    "print(f\"There are {lif.num_images} images in {filename}\")\n",
    "\n",
    "# Let's get the first image\n",
    "index = 3\n",
    "img = lif.get_image(index)\n",
    "print(f\"Imagewith index {index} has dimensions: {img.dims}\")\n",
    "\n",
    "# We extract a 2D frame from the image, the frame is a PIL image object\n",
    "frame = img.get_frame(z=0,t=0,m=0)\n",
    "\n",
    "# And finally display the 2D PIL image, note that PIL images can also be directly\n",
    "# displayed in the notebook.\n",
    "plt.imshow(frame)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's load the all stack in a numpy array\n",
    "M = np.zeros((img.dims.z,img.dims.y,img.dims.x))\n",
    "for k in range(img.dims.z):\n",
    "    M[k,:,:] = img.get_frame(z=k,t=0,m=0)\n",
    "\n",
    "print(\"The shape of the numpy array is\", M.shape)\n",
    "\n",
    "# We can display a slice of the array using numpy\n",
    "plt.imshow(M[5,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Zeiss CZI files\n",
    "Another format that you may encounter for data acquired in Zeiss microscopes is the CZI file format. \n",
    "\n",
    "You can install the czifile module using ```conda install -y -c conda-forge czifile```. Let's open now a CZI file using the czifile module.\n",
    "\n",
    "The module gives access to an multi-dimensional numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import czifile\n",
    "\n",
    "image =  czifile.imread('../data/example.czi')\n",
    "print(\"Shape of the array :\" , image.shape)\n",
    "\n",
    "plt.imshow(image[0,0,0,0,:,:,0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also use the module from the Allen Institute: aicspylibczi based on libczi from Zeiss. For this we need to install it with ``` pip install  aicspylibczi ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from aicspylibczi import CziFile\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pth = Path('../data/example.czi')\n",
    "czi = CziFile(pth)\n",
    "print(\"Size of the image \", czi.size)\n",
    "img, shp = czi.read_image()\n",
    "plt.imshow(img[0,0,0,0,:,:])\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using bioformat\n",
    "Bioformat-python enable to load most image format using javabridge and bioformat. We can install bioformat-python with pip but you'll need to install Oracle JDK 1.6 or later first (https://www.oracle.com/uk/java/technologies/javase-jdk15-downloads.html) and install the module using ``` pip install python-bioformat ```. This approach might be unstable than using the dedicated image readers but provides an uniform access to various file formats.\n",
    "\n",
    "Now let's open an image using bioformat. We need to start a virtual machine first and not forget to stop it when finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import javabridge\n",
    "import bioformats \n",
    "\n",
    "javabridge.start_vm(class_path=bioformats.JARS)\n",
    "img = bioformats.load_image('../data/example.tif', c=0, z=0, t=0)\n",
    "javabridge.kill_vm()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## HDF5 file format\n",
    "\n",
    "The HDF5 format can be used to store images and well as pyramid of various resolutions. This is used in the bigdata viewer (Fiji) and in Imaris for example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Imaris HDF5\n",
    "HDF5 is a hierarchical fileformat that is used by imaris for example (IMS). \n",
    "[https://github.com/imaris/ImarisWriter/blob/master/doc/Imaris5FileFormat.pdf] and [https://github.com/imaris/ImarisWriter]\n",
    "\n",
    "For 8bit datasets, Imaris expect a file with the following data structure \n",
    "- DataSet/ResolutionLevel 0/TimePoint 0/Channel 0/Data (as 8bit unsigned int)\n",
    "- DataSet/ResolutionLevel 0/TimePoint 0/Channel 0/Histogram (as 64bit float)\n",
    " Each 'Channel x' group will have the following attributes: ImageSizeX,ImageSizeY, ImageSizeZ, HistogramMax, HistogramMin.   \n",
    "\n",
    "For 16bit dataset, we have instead:\n",
    "- DataSet/ResolutionLevel 0/TimePoint 0/Channel 0/Data (as 8bit unsigned int)\n",
    "- DataSet/ResolutionLevel 0/TimePoint 0/Channel 0/Histogram1024 (as 64bit float)\n",
    " Each 'Channel x' group will have the following attributes: ImageSizeX,ImageSizeY, ImageSizeZ, HistogramMax1024, HistogramMin1024.   \n",
    "\n",
    " - DataSetInfo/Image with attributes ExtMin0 ExtMin1 ExtMin2 ExtMax0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load a tif file to export to hdf5 as a numpy array [z,c,x,y]\n",
    "img = tifffile.imread( '../data/example.tif')\n",
    "\n",
    "# extract the first channel\n",
    "stack = np.squeeze(img[:,0,:,:])\n",
    "print(f'The stack size is {stack.shape} with type {stack.dtype}')\n",
    "\n",
    "def ims_create_channel(f, stack, resolution, timepoint, channel):\n",
    "    # compute the histogram of the image\n",
    "    [histogram, bin_edges] = np.histogram(stack.ravel(),bins=256)\n",
    "    grp = f.create_group(f'DataSet/ResolutionLevel {resolution}/TimePoint {timepoint}/Channel {channel}')\n",
    "    grp.attrs['ImageSizeX'] = img.shape[2]\n",
    "    grp.attrs['ImageSizeY'] = img.shape[3]\n",
    "    grp.attrs['ImageSizeZ'] = img.shape[0]\n",
    "    grp.attrs['HistogramMax'] = bin_edges[255]\n",
    "    grp.attrs['HistogramMin'] = bin_edges[0]\n",
    "    f['DataSet/ResolutionLevel 0/TimePoint 0/Channel 0/Data'] = stack\n",
    "    f['DataSet/ResolutionLevel 0/TimePoint 0/Channel 0/Histogram'] = histogram\n",
    "    # We add the DataSetInfo/Channel 0 group to store color info on the channel\n",
    "    grp = f.create_group('DataSetInfo/Channel 0')\n",
    "    grp.attrs['Color'] = '1.000 0.000 0.000' # RGB triplet between 0-1 as a string\n",
    "    grp.attrs['ColorMode'] = 'BaseColor' # 'BaseColor' or 'ColorTable'\n",
    "    grp.attrs['ColorOpacity'] = '0.500' # between 0-1 as a string with 3 decimal \n",
    "    grp.attrs['ColorRange'] = '0 255' # color range rendered in imaris\n",
    "\n",
    "def ims_set_image_info(f,shape):\n",
    "    grp = f.create_group('DataSetInfo/Image')\n",
    "    grp.attrs['ExtMin0'] = 0\n",
    "    grp.attrs['ExtMin1'] = 0\n",
    "    grp.attrs['ExtMin2'] = 0\n",
    "    grp.attrs['ExtMax0'] = shape[2] # maximum x coordinate\n",
    "    grp.attrs['ExtMax1'] = shape[1] # maximum y coordinate\n",
    "    grp.attrs['ExtMax2'] = shape[0] # maximum y coordinate\n",
    "\n",
    "with h5py.File('../scratch/example.hdf5', 'w') as f:\n",
    "    # We add the DataSetInfo/Image group\n",
    "    ims_set_image_info(f, stack.shape)\n",
    "    ims_create_channel(f, stack, 0, 0, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's check the content of the file we just created. For this, we create a dump function that explores the HDF5 tree of groups and datasets printing attributes when needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": null
   },
   "outputs": [],
   "source": [
    "\n",
    "def h5dump(obj,sep='  '):\n",
    "    '''\n",
    "    Dump the content of the HDF5 file\n",
    "    '''\n",
    "    # Print attributes of the group/dataset\n",
    "    for akey in obj.attrs.keys():\n",
    "        print(f'{sep}   > {akey} : {obj.attrs[akey]}')\n",
    "    # Go down the tree\n",
    "    if type(obj) in [h5py._hl.group.Group, h5py._hl.files.File]:\n",
    "        for key in obj.keys():\n",
    "            print(f'{sep} - {key}')\n",
    "            h5dump(obj[key],sep+'  ')\n",
    "\n",
    "with h5py.File('../scratch/example.hdf5','r') as f:\n",
    "    h5dump(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Big Data viewer\n",
    "\n",
    "To read and write HDF5 file compatible with the big data viewer, we can use the module npy2bdv which can be installed using pip: ```pip install npy2bdv```. We'll see some basic functionality, more can be found here [[https://github.com/nvladimus/npy2bdv/blob/master/docs/examples/examples_h5writing.ipynb]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import npy2bdv\n",
    "\n",
    "# We use the tifffile module to read the image from disk\n",
    "img = tifffile.imread( '../data/example.tif')\n",
    "# lets set the output filename\n",
    "fname = \"../scratch/example2.h5\"\n",
    "# we create a writer object with 2 channels\n",
    "bdv_writer = npy2bdv.BdvWriter(fname, nchannels=2)\n",
    "# set the attributes\n",
    "bdv_writer.set_attribute_labels('channel', ('488', '561'))\n",
    "\n",
    "for channel in range(2):\n",
    "    bdv_writer.append_view(np.squeeze(img[:,channel,:,:]), channel=channel)\n",
    "\n",
    "bdv_writer.write_xml_file()\n",
    "bdv_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can use h5py to dump the content of this file as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File('../scratch/example2.h5','r') as f:\n",
    "    h5dump(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's load the image we just created : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bdv_editor = npy2bdv.BdvEditor(fname)\n",
    "stack = bdv_editor.read_view(channel=0)\n",
    "print(stack.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Zarr file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We may want to convert the dataset to a parallel file format such as zarr for performance. A parallel file format enable loading and decoding chunks in parallel. If the underlying hardware is not parallel (HDD) then this has limited interest. On the other hand, on a LUSTRE [https://en.wikipedia.org/wiki/Lustre_(file_system)], the file server is tuned to large files and overhead will occur when splitting the file in small chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "import zarr\n",
    "from numcodecs import Blosc\n",
    "\n",
    "# We use the tifffile module to read the image from disk into a numpy array\n",
    "img = tifffile.imread( '../data/example.tif')\n",
    "\n",
    "# By default zarr creates a directory with many files corresponding to data chunk\n",
    "zarr.save('../scratch/example.zarr', img)\n",
    "\n",
    "# We can also define a zip store to store all the files in a single zip file\n",
    "compressor = Blosc(cname='zstd', clevel=3, shuffle=Blosc.BITSHUFFLE)\n",
    "with zarr.ZipStore('../scratch/array.zip', mode='w') as store:\n",
    "    z = zarr.array(img, chunck=(128,128), compressor=compressor, store = store)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can now load a part of a plane of the image into memory. We can use this approach for example to load specific frames of a time lapse sequence sparing the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z1 = zarr.open('../scratch/array.zip', mode='r')\n",
    "plt.imshow(z1[12,0,0:200,0:200])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Image pyramid\n",
    "\n",
    "Image pyramid allow faster browsing of multi resolution images.\n",
    "\n",
    "https://forum.image.sc/t/multiscale-arrays-v0-1/37930\n",
    "[https://github.com/ome/ome-zarr-py/blob/master/ome_zarr/data.py]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.transform import pyramid_gaussian, pyramid_laplacian\n",
    "from scipy.ndimage import zoom\n",
    "import zarr\n",
    "from numcodecs import Blosc\n",
    "import numpy as np\n",
    "\n",
    "# We use the tifffile module to read the image from disk\n",
    "img = tifffile.imread('../data/example.tif')\n",
    "\n",
    "# create a pyramid with data shape as t, c, z, y, x\n",
    "print(img.shape)\n",
    "img = np.moveaxis(img, [0,1,2,3],[1,0,2,3])\n",
    "img = np.reshape(img, [1, img.shape[0], img.shape[1], img.shape[2], img.shape[3]])\n",
    "print(img.shape)\n",
    "\n",
    "# pyramid = list(reversed([zoom(img, 2 ** i, order=3) for i in range(4)]))\n",
    "\n",
    "list(reversed([ 2 ** i for i in range(4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ome_zarr import data\n",
    "p,l = data.coins()\n",
    "data.create_zarr('../scratch/coins.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "store = zarr.DirectoryStore('../scratch/pyr.zarr') \n",
    "grp = zarr.group(store)\n",
    "paths = []\n",
    "\n",
    "for path, dataset in enumerate(pyramid):\n",
    "    grp.create_dataset(str(path), data=pyramid[path])\n",
    "    paths.append({\"path\": str(path)})\n",
    "\n",
    "multiscales = [{\"version\": \"0.1\", \"datasets\": paths}]\n",
    "grp.attrs[\"multiscales\"] = multiscales\n",
    "image_data = {\n",
    "    \"channels\": [\n",
    "        {\n",
    "            \"color\": \"FF0000\",\n",
    "            \"window\": {\"start\": 0, \"end\": 1},\n",
    "            \"label\": \"Red\",\n",
    "            \"active\": True,\n",
    "        },\n",
    "        {\n",
    "            \"color\": \"00FF00\",\n",
    "            \"window\": {\"start\": 0, \"end\": 1},\n",
    "            \"label\": \"Green\",\n",
    "            \"active\": True,\n",
    "        }\n",
    "    ],\n",
    "    \"rdefs\": {\"model\": \"color\"},\n",
    "}\n",
    "grp.attrs[\"omero\"] = image_data      \n",
    "print(grp.info)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6cb53e4cae58c19d01a25dc0dace12f397db98da729074f7b2c82d85c25fd9c"
  },
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "name": "example1-loading-data.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
