{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Deconvolution\n",
                "\n",
                "Images acquired on a microscope are blurred as the result of the diffraction of the light collected by the objective. The blur can be modelled as convolution of the image by the point spread function (PSF). The optical transfer function is defined as the Fourier transform of the PSF and the convolution theorem indicates that the Fourier transform (FT) of the recorded image is the product of the optical transfer function and the FT of the sample. The optical transfer function is zero beyond the diffraction limit defined in the xy plane as half the ratio of the wavelength and the numerical aperture of the objective. This result as unobservable frequencies in the acquired image.\n",
                "\n",
                "Recovering the fluorophore density of the sample from an acquired image amount at inversing the convolution process and is called deconvolution. As convolution is the product of the OTF by the FT of the sample, deconvolution should be the division of the FT of the image by the OTF. However, the OTF being zero outside the resolution limit, the division is ill posed and simply amplify the noise of the acquired image.\n",
                "\n",
                "Various strategies can be used then to recover the fine structure of the sample whilst mitigating the noise amplification. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run this cell is your are developing the code locally\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import sys\n",
                "import site\n",
                "site.addsitedir('../') "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We start by generating an optical transfert function that represent the action\n",
                "of the microscope on the sample."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from skimage.metrics import mean_squared_error\n",
                "from mug import deconvolution\n",
                "from mug import data\n",
                "from mug import utils\n",
                "\n",
                "shape = [64,256,256]\n",
                "pixel_size = [100,80,80]\n",
                "otf, psf = deconvolution.otf_generator(shape,pixel_size,500,1,1.3)([0,0,0,0.0])\n",
                "plt.imshow(utils.slice3d(np.log(1e-6+np.fft.fftshift(psf))))\n",
                "plt.axis('off')\n",
                "plt.title('Point spread function');"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now create a test image and convolve it with the blur of the microscope."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate a test sample\n",
                "sample = 0.1+1000 * data.fibers(shape,pixel_size,L=500,smooth=30)\n",
                "# Simulate the image of the sample\n",
                "blurred = deconvolution.blur(sample, otf)\n",
                "# Add some noise\n",
                "blurred = np.random.poisson(blurred)\n",
                "# Compute the MSE between the blurred image and the original sample\n",
                "mse_blurred = mean_squared_error(sample, blurred)\n",
                "# Display the images\n",
                "utils.show_image_list(\n",
                "    [utils.mip3d(x) for x in [sample, blurred]],\n",
                "    ['Sample', f'Blurred (MSE:{mse_blurred:.2f})'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "estimate_rl, dkl = deconvolution.deconvolve_richardson_lucy(blurred, otf)\n",
                "mse_rl = mean_squared_error(sample, estimate_rl)\n",
                "utils.show_image_list(\n",
                "    [utils.mip3d(x) for x in [sample, estimate_rl]],\n",
                "    ['Sample', f'R-L (MSE:{mse_rl:.2f})'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "estimate_rlhb, dkl_hb = deconvolution.deconvolve_richardson_lucy_heavy_ball(blurred, otf)\n",
                "mse_rlhb = mean_squared_error(sample, estimate_rlhb)\n",
                "utils.show_image_list(\n",
                "    [utils.mip3d(x) for x in [sample, estimate_rlhb]],\n",
                "    ['Sample', f'R-L HB (MSE:{mse_rlhb:.2f})'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "estimate_gm, dkl_gm = deconvolution.deconvolve_gold_meinel(blurred, otf, 0, 5, 1.3, smooth=1.)\n",
                "mse_gm = mean_squared_error(sample, estimate_gm)\n",
                "utils.show_image_list(\n",
                "    [utils.mip3d(x) for x in [blurred, estimate_gm]],\n",
                "    ['Sample', f'G-M (MSE:{mse_gm:.2f})'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(dkl)\n",
                "plt.plot(dkl_hb)\n",
                "plt.plot(dkl_gm)\n",
                "plt.title('Standard versus accelerated R-L')\n",
                "plt.xlabel('Iterations')\n",
                "plt.ylabel('Kullback-Leibler divergence')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "estimate_w = deconvolution.deconvolve_wiener(blurred, otf, 60.)\n",
                "estimate_w = np.maximum(estimate_w, 0)\n",
                "mse_w = mean_squared_error(sample, estimate_w)\n",
                "\n",
                "utils.show_image_list(\n",
                "    [utils.mip3d(x) for x in [sample, blurred, estimate_w]],\n",
                "    ['Sample', 'Blurred', f'Wiener {mse_w:.2f}'])\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "utils.show_image_list(\n",
                "    [utils.mip3d(utils.power_spectrum_density(x)) for x in [sample, blurred, estimate_w]],\n",
                "    ['Sample', 'Blurred', f'Wiener {mse_w:.2f}'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "deconvolved_dr = deconvolution.deconvolve_dr(blurred, otf, 0.001, 20)\n",
                "mse_dr = mean_squared_error(sample, deconvolved_dr)\n",
                "\n",
                "utils.show_image_list(\n",
                "    [utils.mip3d(x) for x in [sample, blurred, deconvolved_dr]],\n",
                "    ['Sample', 'Blurred', f'Iterative {mse_dr:.2f}'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "estimate_tv = deconvolution.deconvolve_total_variation(blurred, otf, pixel_size=pixel_size, regularization=0.000001)\n",
                "mse_tv = mean_squared_error(sample, estimate_tv)\n",
                "utils.show_image_list(\n",
                "    [utils.mip3d(x) for x in [sample, blurred, estimate_tv]],\n",
                "    ['Sample', 'Blurred', f'TV {mse_tv:.2f}'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "utils.show_image_list(\n",
                "    [utils.mip3d(utils.power_spectrum_density(x)) for x in [sample, blurred, estimate_tv]],\n",
                "    ['Sample', 'Blurred', f'TV {mse_tv:.2f}'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f = np.zeros(shape)\n",
                "f.shape\n",
                "b = 8\n",
                "f[32-2*b:32+2*b,128-b:128+b,32:224] = 1\n",
                "f = deconvolution.blur(f,otf)\n",
                "f,dkl = deconvolution.deconvolve_richardson_lucy(f, otf, 1e-4, 30)\n",
                "plt.imshow(utils.mip3d(f))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Old code"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "def zernike_polynomial(r,t,coefficients):\n",
                "    '''\n",
                "    Zernike polynomials\n",
                "    Parameters\n",
                "    ----------\n",
                "    r : radius\n",
                "    t : angle\n",
                "    coefficients: coefficients (up to 15)\n",
                "    Result\n",
                "    ------\n",
                "    P : polynomial evaluated on rho, theta\n",
                "    '''\n",
                "    if coefficients is None:\n",
                "        return np.zeros(r,shape)\n",
                "    if coefficients.shape[0] < 15:\n",
                "        coefficients = np.pad(coefficients,(0,15-coefficients.shape[0]))\n",
                "    r2 = np.square(r)\n",
                "    r3 = np.power(r,3.0)\n",
                "    r4 = np.power(r,4.0)\n",
                "    c = np.cos(t)\n",
                "    s = np.sin(t)\n",
                "    c2 = np.cos(2*t)\n",
                "    s2 = np.sin(2*t)\n",
                "    c3 = np.cos(3*t)\n",
                "    s3 = np.sin(3*t)\n",
                "    P = np.zeros(r.shape)\n",
                "    P = P + coefficients[0] * r * c\n",
                "    P = P + coefficients[1] * r * s\n",
                "    P = P + coefficients[2] * (2. * r2 - 1.)\n",
                "    P = P + coefficients[3] * r2 * c2\n",
                "    P = P + coefficients[4] * r2 * s2\n",
                "    P = P + coefficients[5] * (3.*r2-2.) * r * c\n",
                "    P = P + coefficients[6] * (3.*r2-2.) * r * s\n",
                "    P = P + coefficients[7] * (6.*r4 - 6.*r2 + 1.)\n",
                "    P = P + coefficients[8] * r3 * c3\n",
                "    P = P + coefficients[9] * r3 * s3\n",
                "    P = P + coefficients[10] * (4.*r3 - 3) * r2 * c2\n",
                "    P = P + coefficients[11] * (4.*r3 - 3) * r2 * s2\n",
                "    P = P + coefficients[12] * (10 * r4 - 12 * r2 + 3) * r  * c\n",
                "    P = P + coefficients[13] * (10 * r4 - 12 * r2 + 3) * r  * s\n",
                "    P = P + coefficients[13] * ((20 * r4 - 30 * r2 + 12)  * r2 - 1)\n",
                "    P = np.where(r<1.0,P,0)\n",
                "    return P\n",
                "\n",
                "x,y = np.meshgrid(np.linspace(-1,1,32),np.linspace(-1,1,32))\n",
                "rho = np.sqrt(np.square(x)+np.square(y))\n",
                "theta = np.arctan2(y,x)\n",
                "coefficients = np.array([0,0,1,0,0,0,0])\n",
                "P = zernike_polynomial(rho,theta,coefficients)\n",
                "plt.imshow(P)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import math\n",
                "import matplotlib.pyplot as plt\n",
                "import time\n",
                "\n",
                "def generate_otf3d_grid(shape, pixel_size):\n",
                "    \"\"\"\n",
                "    Generate a grid on which to evaluate the optical transfer function\n",
                "    Parameters\n",
                "    ----------\n",
                "    shape : list [nx,ny,nz] giving the shape of the final array\n",
                "    pixel_size : sampling in [x,y,z]    \n",
                "    Returns\n",
                "    -------\n",
                "    kx,ky,kz,z: frequency grid in x and y and spatial space in z\n",
                "    \"\"\"\n",
                "    f = [np.fft.fftfreq(n, pixel_size[k]) for k, n in enumerate(shape)]\n",
                "    ez = np.concatenate((np.arange(0,shape[2]//2), np.arange((-shape[2])//2,0))) * pixel_size[2]\n",
                "    [kx,ky,kz] = np.meshgrid(*f)\n",
                "    z = np.meshgrid(f[0],f[1],ez)[2]\n",
                "    return kx,ky,kz,z\n",
                "\n",
                "\n",
                "def generate_otf3d_on_grid(grid,NA,wavelength,medium_refractive_index,aberrations=None):\n",
                "    \"\"\"\n",
                "    Generate a diffraction limited wide field optical transfer function and point spread function\n",
                "    Parameters\n",
                "    ----------\n",
                "    grid : tuple [kx,ky,z] with grid on which to evaluate the otf\n",
                "    pixel_size : sampling in [x,y,z]\n",
                "    NA : numerical aperture\n",
                "    wavelength : wavelength of the emitted light\n",
                "    medium_refractive_index : refractive index of the immersion medium\n",
                "    Returns\n",
                "    --------\n",
                "    otf : the optical transfer function as an array of shape 'shape'\n",
                "    psf : the point spread function as an array of shape 'shape' centerd in 0,0,0\n",
                "    \"\"\"\n",
                "    d2 = np.square(grid[0]) + np.square(grid[1])\n",
                "    rho = np.sqrt(d2) * wavelength / NA\n",
                "    theta = np.arctan2(grid[1],grid[0])\n",
                "    P = np.where(rho <= 1.0, 1.0, 0.0)\n",
                "    defocus = grid[3] * np.sqrt(np.clip((medium_refractive_index / wavelength)**2 - d2,0,None))\n",
                "    phi = zernike_polynomial(rho,theta,aberrations)\n",
                "    psf = np.square(np.abs(np.fft.fft2(P * np.exp(2j * math.pi * (defocus+phi)),axes=[0,1])))\n",
                "    psf = psf / psf.sum()\n",
                "    otf = np.fft.fftn(psf)\n",
                "    return otf, psf\n",
                "\n",
                "def generate_otf3d(shape,pixel_size,wavelength,NA,medium_refractive_index,aberrations=None):\n",
                "    \"\"\"\n",
                "    Generate a diffraction limited wide field optical transfer function and point spread function\n",
                "    Parameters\n",
                "    ----------\n",
                "    shape : list [nx,ny,nz] giving the shape of the final array\n",
                "    pixel_size : sampling in [x,y,z]\n",
                "    NA : numerical aperture\n",
                "    wavelength : wavelength of the emitted light\n",
                "    medium_refractive_index : refractive index of the immersion medium\n",
                "    Returns\n",
                "    --------\n",
                "    otf : the optical transfer function as an array of shape 'shape'\n",
                "    psf : the point spread function as an array of shape 'shape' centerd in 0,0,0\n",
                "    \"\"\"\n",
                "    grid = generate_otf3d_grid(shape, pixel_size)\n",
                "    return generate_otf3d_on_grid(grid,NA,wavelength,medium_refractive_index,aberrations)\n",
                "\n",
                "def generate_otf3d(shape,pixel_size,wavelength,NA,medium_refractive_index,aberrations=None):\n",
                "    f = [np.fft.fftfreq(n, pixel_size[k]) for k, n in enumerate(shape)]\n",
                "    ez = np.concatenate((np.arange(0,shape[2]//2), np.arange((-shape[2])//2,0))) * pixel_size[2]\n",
                "    [kx,ky,kz] = np.meshgrid(*f)\n",
                "    z = np.meshgrid(f[0],f[1],ez)[2]\n",
                "    d2 = np.square(kx) + np.square(ky)\n",
                "    rho = np.sqrt(d2) * wavelength / NA\n",
                "    theta = np.arctan2(ky, kx)\n",
                "    P = np.where(rho <= 1.0, 1.0, 0.0)\n",
                "    defocus = z * np.sqrt(np.clip((medium_refractive_index / wavelength)**2 - d2,0,None))\n",
                "    phase = defocus + zernike_polynomial(rho,theta,aberrations)\n",
                "    psf = np.square(np.abs(np.fft.fft2(P * np.exp(2j * math.pi * phase),axes=[0,1]))\n",
                "    psf = psf / psf.sum()\n",
                "    otf = np.fft.fftn(psf)\n",
                "    return otf, psf\n",
                "\n",
                "\n",
                "\n",
                "shape = [64,64,32] \n",
                "pixel_size = [100,100,300] \n",
                "wavelength = 500\n",
                "NA = 1\n",
                "medium_refractive_index = 1.3\n",
                "aberrations = np.array([0,0,0,0.5])\n",
                "start = time.time()\n",
                "otf,psf = generate_otf3d(shape,pixel_size,wavelength,NA,medium_refractive_index,aberrations)\n",
                "print(f'Elsapsed time {time.time()-start}')\n",
                "\n",
                "start = time.time()\n",
                "otf,psf = generate_otf3d(shape,pixel_size,wavelength,NA,medium_refractive_index,aberrations)\n",
                "\n",
                "plt.imshow(np.fft.fftshift(psf[:,0,:]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import scipy.ndimage\n",
                "\n",
                "def generate_test_image(shape,N=10,L=100,smooth=10):\n",
                "    \"\"\"\n",
                "    Generate a test image with fibers\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    shape : list of int giving the shape of the generated image\n",
                "    N : number of fibers\n",
                "    L : number of points in each fiber\n",
                "    smooth : smoothness of the fibers\n",
                "    \n",
                "    Output\n",
                "    ------\n",
                "    img : numpy array of given shape normalized between 0 and 1\n",
                "    \"\"\"\n",
                "    D = len(shape)\n",
                "    # generate points on smooth curves as a N x L x D array\n",
                "    P = np.tile(np.repeat(np.reshape(np.array(shape), [1,1,D]), N, axis=0) * (.1 + .8 * np.random.rand(N,1,D)), [1,L,1])\n",
                "    P = P + np.cumsum(scipy.ndimage.gaussian_filter1d(2*np.random.randn(N,L,D), smooth, axis=1),axis=1)\n",
                "    space = tuple([np.arange(k) for k in shape])\n",
                "    X = np.meshgrid(*space)\n",
                "    img = np.zeros(shape)\n",
                "    for p in np.reshape(P,(N*L,D)):\n",
                "        img = img + np.exp(-0.5*np.sum(np.stack([np.square(p[k]-X[k]) for k in range(D)]), axis=0))\n",
                "    img = img / img.max()\n",
                "    return img\n",
                "\n",
                "img = generate_test_image(shape,10,100)\n",
                "plt.imshow(np.amax(img,axis=2))\n",
                "plt.title('Simulated sample')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To simulate an image acquired by a microscope, we multiply in Fourier space the sample by the optical transfer function. We also add some Poisson noise to emulate the photon limited nature of the acquisition process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = 1000 * np.real(np.fft.ifftn(np.fft.fftn(img) * otf))\n",
                "data = np.random.poisson(data)\n",
                "plt.imshow(np.amax(data, 2))\n",
                "plt.title('Simulated data')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We have simulated a realistic image. We will now try to recover the original sample using a deconvolution algorithm. We implement here the Richardson-Lucy deconvolution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def kulback_leibler_divergence(data,estimate,otf,background):\n",
                "    \"\"\"\n",
                "    Compute the kullback Leibler divergence\n",
                "    Parameters\n",
                "    ----------\n",
                "    data       : numpy array \n",
                "    estimate   : estimate\n",
                "    otf        : numpy array of the same size than data\n",
                "    background : background level\n",
                "    Result\n",
                "    ------\n",
                "    The kullback Leibler divergence\n",
                "    \"\"\"\n",
                "    blurred = np.real(np.fft.ifftn(otf * np.fft.fftn(estimate+background)))\n",
                "    return np.mean(blurred - data + data * np.log(np.clip(data/blurred,a_min=1e-6,a_max=None))) \n",
                "\n",
                "def deconvolve_richardson_lucy(data, otf, background=0, iterations=100):\n",
                "    \"\"\" \n",
                "    Deconvolve data according to the given otf using a Richardson-Lucy algorithm\n",
                "    Parameters\n",
                "    ----------\n",
                "    data       : numpy array\n",
                "    otf        : numpy array of the same size than data\n",
                "    background : background level\n",
                "    iterations : number of iterations\n",
                "    Result\n",
                "    ------\n",
                "    estimate   : estimated image\n",
                "    dkl        : Kullback Leibler divergence\n",
                "    \"\"\"\n",
                "    estimate = np.clip(np.real(np.fft.ifftn(otf * np.fft.fftn(data-background))), a_min=1e-6, a_max=None)\n",
                "    dkl = np.zeros(iterations)\n",
                "    for k in range(iterations):\n",
                "        blurred = np.clip(np.real(np.fft.ifftn(otf * np.fft.fftn(estimate+background))), a_min=1e-6, a_max=None)\n",
                "        ratio = data / blurred\n",
                "        estimate = estimate * np.real(np.fft.ifftn(otf * np.fft.fftn(ratio)))\n",
                "        dkl[k] = np.mean(blurred - data + data * np.log(np.clip(ratio,a_min=1e-6,a_max=None)))\n",
                "    return estimate, dkl\n",
                "\n",
                "deconvolved1, dkl1 = deconvolve_richardson_lucy(data,otf,0,200)\n",
                "fig, ax = plt.subplots(1,4,figsize=[20,5])\n",
                "ax[0].imshow(np.amax(img, 2))\n",
                "ax[1].imshow(np.amax(data, 2))\n",
                "ax[2].imshow(np.amax(deconvolved1, 2))\n",
                "ax[3].plot(dkl1)\n",
                "ax[3].set_title('Kullback leibler divergence')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's now implement an accelerate version of the Richardson Lucy using the principle of heavy ball acceleration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def deconvolve_richardson_lucy_heavy_ball(data, otf, background, iterations):\n",
                "    \"\"\" \n",
                "    Deconvolve data according to the given otf using a scaled heavy ball Richardson-Lucy algorithm\n",
                "    Parameters\n",
                "    ----------\n",
                "    data       : numpy array\n",
                "    otf        : numpy array of the same size than data\n",
                "    iterations : number of iterations\n",
                "    Result\n",
                "    ------\n",
                "    estimate   : estimated image\n",
                "    dkl        : the kullback leibler divergence (should tend to 1/2)\n",
                "    Note\n",
                "    ----\n",
                "    https://doi.org/10.1109/tip.2013.2291324\n",
                "    \"\"\"\n",
                "    old_estimate = np.clip(np.real(np.fft.ifftn(otf * np.fft.fftn(data - background))), a_min=0, a_max=None)\n",
                "    estimate = data\n",
                "    dkl = np.zeros(iterations)\n",
                "    for k in range(iterations):\n",
                "        beta = (k-1.0) / (k+2.0)\n",
                "        prediction = estimate + beta * (estimate -  old_estimate)\n",
                "        blurred = np.clip(np.real(np.fft.ifftn(otf * np.fft.fftn(prediction + background))), a_min=1e-6, a_max=None)\n",
                "        ratio = data / blurred\n",
                "        gradient = 1.0 - np.real(np.fft.ifftn(otf * np.fft.fftn(ratio)))\n",
                "        old_estimate = estimate\n",
                "        estimate = np.clip(prediction - estimate * gradient, a_min=0.1, a_max=None)\n",
                "        dkl[k] = np.mean(blurred - data + data * np.log(np.clip(ratio,a_min=1e-6, a_max=None)))\n",
                "    return estimate, dkl\n",
                "\n",
                "deconvolved2,dkl2 = deconvolve_richardson_lucy_heavy_ball(data, otf, 0, 200)\n",
                "fig, ax = plt.subplots(1,5,figsize=[20,5])\n",
                "ax[0].imshow(np.amax(img, 2))\n",
                "ax[1].imshow(np.amax(data, 2))\n",
                "ax[2].imshow(np.amax(deconvolved1, 2))\n",
                "ax[3].imshow(np.amax(deconvolved2, 2))\n",
                "ax[4].plot(dkl1)\n",
                "ax[4].plot(dkl2)\n",
                "mse1 = np.mean(np.square(deconvolved1 - img))\n",
                "mse2 = np.mean(np.square(deconvolved2 - img))\n",
                "print(f'MSE11 {mse1} MSE2 {mse2}' )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "def deconvolve_richardson_lucy_heavy_ball_torch(data, otf, background, iterations):\n",
                "    \"\"\" \n",
                "    Deconvolve data according to the given otf using a scaled heavy ball Richardson-Lucy algorithm\n",
                "    Parameters\n",
                "    ----------\n",
                "    data       : torch tensor\n",
                "    otf        : optical transfer function\n",
                "    background : bakground level\n",
                "    iterations : number of iterations\n",
                "    Result\n",
                "    ------\n",
                "    estimate   : estimated image\n",
                "    dkl        : the kullback leibler divergence (should tend to 1/2)\n",
                "    Note\n",
                "    ----\n",
                "    https://doi.org/10.1109/tip.2013.2291324\n",
                "    Needs pytorch (>1.9))\n",
                "    \"\"\"\n",
                "    data = torch.from_numpy(data.astype(float))\n",
                "    otf = torch.from_numpy(otf.astype(complex))\n",
                "    old_estimate = torch.clamp(torch.real(torch.fft.ifftn(otf * torch.fft.fftn(data))), min=1e-6)\n",
                "    estimate = data\n",
                "    dkl = torch.zeros(iterations, dtype=float)\n",
                "    for k in range(iterations):\n",
                "        beta = (k-1.0) / (k+2.0)\n",
                "        prediction = estimate + beta * (estimate -  old_estimate)\n",
                "        blurred = torch.clamp(torch.real(torch.fft.ifftn(otf * torch.fft.fftn(prediction + background))), min=1e-6)\n",
                "        ratio = data / blurred\n",
                "        gradient = 1.0 - torch.real(torch.fft.ifftn(otf * torch.fft.fftn(ratio)))\n",
                "        old_estimate = estimate\n",
                "        estimate = torch.clamp(prediction - estimate * gradient, min=1e-6)\n",
                "        dkl[k] = torch.mean(blurred - data + data * torch.log(torch.clamp(ratio,min=1e-6)))\n",
                "    return estimate.numpy(), dkl.numpy()\n",
                "\n",
                "deconvolved3, dkl3 = deconvolve_richardson_lucy_heavy_ball_torch(data, otf, 0, 200)\n",
                "fig, ax = plt.subplots(1,6,figsize=[20,5])\n",
                "ax[0].imshow(np.amax(img, 2))\n",
                "ax[1].imshow(np.amax(data, 2))\n",
                "ax[2].imshow(np.amax(deconvolved1, 2))\n",
                "ax[3].imshow(np.amax(deconvolved2, 2))\n",
                "ax[4].imshow(np.amax(deconvolved3, 2))\n",
                "ax[5].plot(dkl1)\n",
                "ax[5].plot(dkl2)\n",
                "ax[5].plot(dkl3)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import napari\n",
                "\n",
                "viewer = napari.view_image(img, scale=[10,1,1])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch import nn\n",
                "\n",
                "def generate_otf3d_on_grid_torch(grid,NA,wavelength,medium_refractive_index,phi):\n",
                "    \"\"\"\n",
                "    Generate a diffraction limited wide field optical transfer function and point spread function\n",
                "    Parameters\n",
                "    ----------\n",
                "    grid : tuple [kx,ky,z] with grid on which to evaluate the otf\n",
                "    pixel_size : sampling in [x,y,z]\n",
                "    NA : numerical aperture\n",
                "    wavelength : wavelength of the emitted light\n",
                "    medium_refractive_index : refractive index of the immersion medium\n",
                "    Returns\n",
                "    --------\n",
                "    otf : the optical transfer function as an array of shape 'shape'\n",
                "    psf : the point spread function as an array of shape 'shape' centerd in 0,0,0\n",
                "    \"\"\"\n",
                "\n",
                "    d2 = torch.square(grid[0]) + torch.square(grid[1])\n",
                "    rho = torch.sqrt(d2) * wavelength / NA\n",
                "    P = torch.where(rho <= 1.0, 1.0, 0.0)\n",
                "    defocus = grid[3] * torch.sqrt(np.clip((medium_refractive_index / wavelength)**2 - d2,0,None))\n",
                "    psf = torch.square(torch.abs(torch.fft.fft2(P * torch.exp(2j * math.pi * (defocus + phi)),axes=[0,1])))\n",
                "    psf = psf / psf.sum()\n",
                "    otf = torch.fft.fftn(psf)\n",
                "    return otf, psf\n",
                "\n",
                "class PSFNet(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(PSFNet,self).__init__()\n",
                "        shape = [64,64,32]\n",
                "        pixel_size = [100.,100.,100.]\n",
                "        medium_refractive_index = 1.3\n",
                "        wavelength = 500.\n",
                "        NA = 1.\n",
                "        grid = generate_otf3d_grid([64,64,32],[100,100,100])\n",
                "        d2 = torch.square(grid[0]) + torch.square(grid[1])\n",
                "        rho = np.sqrt(d2) * wavelength / NA\n",
                "        self.P = torch.where(rho <= 1.0, 1.0, 0.0)\n",
                "        self.defocus = torch.from_numpy( grid[3]) * torch.sqrt(np.clip((medium_refractive_index / wavelength)**2 - d2,0,None))\n",
                "\n",
                "        self.phi = torch.nn.Parameter(torch.zeros(self.defocus.size))\n",
                "    def forward(self):\n",
                "        psf = torch.square(torch.abs(torch.fft.fft2(self.P * torch.exp(2j * math.pi * (self.defocus + phi)), axes=[0,1])))\n",
                "\n",
                "model = PSFNet()\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# function least square fit in pytorch\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# create the data points\n",
                "n=100\n",
                "x = torch.ones(n,2)\n",
                "x[:,0].uniform_(-1.,1.)\n",
                "a = torch.Tensor([3.,2.])\n",
                "y = x@a + 0.1 * torch.randn(n)\n",
                "plt.scatter(x[:,0],y)\n",
                "print(x.shape)\n",
                "''''''\n",
                "def mse(y_hat,y):\n",
                "    return ((y_hat-y)**2).mean()\n",
                "\n",
                "a = torch.tensor([3.1,2.5])\n",
                "a = torch.nn.Parameter(a)\n",
                "def update(lr):\n",
                "    y_hat = x@a\n",
                "    loss = mse(y,y_hat)\n",
                "    #if t % 10 == 0: print(loss,a)\n",
                "    loss.backward() # compte the gradient\n",
                "    with torch.no_grad():\n",
                "        a.sub_(lr*a.grad) # evolve a-=lr*grad\n",
                "        a.grad.zero_() # set the gradient to 0\n",
                "    \n",
                "lr = 0.01\n",
                "for t in range(100):\n",
                "    update(lr)\n",
                "print(a)\n",
                "plt.plot(x[:,0],x@a.detach().numpy(),'r.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1D gaussian fitting using pytorch and gradient descent    \n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "gauss = lambda x,p : torch.exp(-torch.square(x-p[0]) / p[1])\n",
                "\n",
                "# create the data points\n",
                "n = 100\n",
                "x = torch.ones(n)\n",
                "x[:].uniform_(-10.,10.)\n",
                "a = torch.Tensor([3.,2.])\n",
                "y = gauss(x,a) + 0.01 * torch.randn(n)\n",
                "plt.scatter(x,y)\n",
                "print(x.shape)\n",
                "\n",
                "# define the loss function\n",
                "def mse(y_hat,y):\n",
                "    return ((y_hat-y)**2).mean()\n",
                "\n",
                "def update(lr,lossfun,fun,x,a):\n",
                "    y_hat = fun(x,a)\n",
                "    loss = lossfun(y,y_hat)\n",
                "    loss.backward() # compte the gradient\n",
                "    with torch.no_grad():\n",
                "        a.sub_(lr*a.grad) # evolve a-=lr*grad\n",
                "        a.grad.zero_() # set the gradient to 0\n",
                "    return a, loss\n",
                "\n",
                "a = torch.tensor([3.1,3])\n",
                "a = torch.nn.Parameter(a)  \n",
                "lr = 1\n",
                "for t in range(1000):\n",
                "    a, loss = update(lr,mse,gauss,x,a)\n",
                "print(a)\n",
                "x0 = torch.linspace(-10,10,100)\n",
                "plt.plot(x0,gauss(x0,a).detach().numpy(),'r-')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.optimize import curve_fit\n",
                "import time\n",
                "\n",
                "# levenberg marquardt in pytorch\n",
                "def curve_fit_levenberg_marquardt_torch(model, xdata, ydata, init, niter=500, autograd=False):\n",
                "    '''\n",
                "    Levenberg marquardt using pytorch's autodiff capabilities\n",
                "    Parameters\n",
                "    ----------\n",
                "    model : function to fit lambda x,beta: ...\n",
                "    xdata : torch.Tensor with x data points\n",
                "    ydata : torch.Tensor with y data points\n",
                "    init : torch.Tensor with starting point\n",
                "    niter : number of iterations\n",
                "    autograd: enable automatic differentiation\n",
                "    Result\n",
                "    ------\n",
                "    beta : estimated parameters\n",
                "    cov : covariance matrix\n",
                "    loss : list of mean square error \n",
                "    '''\n",
                "    n = init.numel()\n",
                "    m = xdata.numel()\n",
                "    beta = init.clone()\n",
                "    beta.resize_(n)\n",
                "    loss = []\n",
                "    l = 0.001\n",
                "    p = 1e-3\n",
                "    for k in range(niter):\n",
                "        yhat = model(xdata, beta)\n",
                "        residuals = yhat - ydata\n",
                "        loss.append(torch.mean(torch.square(residuals)))\n",
                "        if autograd:\n",
                "            J = torch.autograd.functional.jacobian(model,(x,beta),vectorize=True)[1]     \n",
                "        else:\n",
                "            J = torch.zeros(m, n, device=xdata.device)\n",
                "            for i in range(n):\n",
                "                h = torch.zeros(n, device=xdata.device)\n",
                "                h[i] += p\n",
                "                J[:,i] = (model(xdata, beta + h) - yhat) / p\n",
                "        JtJ = J.t() @ J\n",
                "        A = JtJ + l * torch.diag(JtJ)\n",
                "        delta = torch.linalg.solve(A , J.t() @ residuals)\n",
                "        beta.sub_(delta)\n",
                "        if k > 1:\n",
                "            if loss[k] < loss[k-1]:\n",
                "                l /= 5\n",
                "            else:\n",
                "                l *= 2\n",
                "                beta.add_(delta)\n",
                "            if torch.abs(loss[k]-loss[k-1]) / loss[k] < 1e-2 :\n",
                "                break\n",
                "\n",
                "    residuals = model(xdata, beta) - ydata \n",
                "    loss.append(torch.mean(torch.square(residuals)))     \n",
                "    cov = A.inverse() * loss[-1]\n",
                "    return beta, cov, loss\n",
                "\n",
                "gauss = lambda x,p : torch.exp(-torch.square(x-p[0]) / p[1])\n",
                "\n",
                "n = 2000\n",
                "x = torch.ones(n)\n",
                "x.uniform_(-10.,10.)\n",
                "a = torch.Tensor([3.,2.])\n",
                "y = gauss(x,a) + 0.01 * torch.randn(n)\n",
                "init = torch.Tensor([1.5,2.5])\n",
                "\n",
                "# pytorch version\n",
                "start = time.time()\n",
                "ahat,cov,loss = curve_fit_levenberg_marquardt_torch(gauss,x,y,init,30,True)\n",
                "print(f'Elapsed time {time.time()-start}, loss {loss[-1]}')\n",
                "\n",
                "start = time.time()\n",
                "ahat1,cov1,loss1 = curve_fit_levenberg_marquardt_torch(gauss,x,y,init,30,False)\n",
                "print(f'Elapsed time {time.time()-start}, loss {loss1[-1]}')\n",
                "\n",
                "# scipy version\n",
                "def gauss2(x,p0,p1):\n",
                "    return np.exp(-np.square(x-p0) / p1)\n",
                "\n",
                "start = time.time()\n",
                "ahat2,cov2 = curve_fit(gauss2, x.numpy(), y.numpy(), init.numpy())\n",
                "loss2 = np.mean(np.square(gauss2(x.numpy(), ahat2[0], ahat2[1]) - y.numpy()))\n",
                "print(f'Elapsed time {time.time()-start}, loss {loss2}')\n",
                "\n",
                "fig,ax = plt.subplots(1,2)\n",
                "ax[0].semilogy(loss)\n",
                "ax[1].plot(x,y,'.')\n",
                "ax[1].plot(torch.linspace(-10,10,100),gauss(torch.linspace(-10,10,100),init),'b')\n",
                "ax[1].plot(torch.linspace(-10,10,100),gauss(torch.linspace(-10,10,100),ahat),'r')\n",
                "ax[1].plot(torch.linspace(-10,10,100),gauss(torch.linspace(-10,10,100),ahat2),'k--')\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def f(*args):\n",
                "    ret = []\n",
                "    for x in args:\n",
                "        ret.append(2*x+1)\n",
                "    return tuple(ret)\n",
                "\n",
                "x = torch.linspace(0,10,11)\n",
                "torch.autograd.functional.jacobian(f,torch.split(x,1))\n",
                "\n",
                "def f(x,a):\n",
                "    return a[0] * x + a[1] + a[2]*x*x\n",
                "\n",
                "x = torch.linspace(0,10,11)\n",
                "a = torch.ones(3)\n",
                "J = torch.autograd.functional.jacobian(f,(x,a))[1]\n",
                "print(a.shape)\n",
                "J\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def fit_levenberg_marquardt_torch(model, ydata, init, niter=500, autograd=False):\n",
                "    '''\n",
                "    Levenberg marquardt using pytorch's autodiff capabilities\n",
                "    Parameters\n",
                "    ----------\n",
                "    model : function to fit lambda beta: ...\n",
                "    ydata : torch.Tensor with y data points\n",
                "    init : torch.Tensor with starting point\n",
                "    niter : number of iterations\n",
                "    autograd: enable automatic differentiation\n",
                "    Result\n",
                "    ------\n",
                "    beta : estimated parameters\n",
                "    cov : covariance matrix\n",
                "    loss : list of mean square error \n",
                "    '''\n",
                "    n = init.numel()\n",
                "    #m = xdata.numel()\n",
                "    beta = init.clone()\n",
                "    beta.resize_(n)\n",
                "    loss = []\n",
                "    l = 0.001\n",
                "    p = 1e-3\n",
                "    for k in range(niter):\n",
                "        yhat = model(beta)\n",
                "        residuals = yhat - ydata\n",
                "        loss.append(torch.mean(torch.square(residuals)))\n",
                "        if autograd:\n",
                "            J = torch.autograd.functional.jacobian(model,a,vectorize=True)[1]     \n",
                "        else:\n",
                "            J = torch.zeros(m, n, device=ydata.device)\n",
                "            for i in range(n):\n",
                "                h = torch.zeros(n, device=ydata.device)\n",
                "                h[i] += p\n",
                "                J[:,i] = (model(beta + h) - yhat) / p\n",
                "        JtJ = J.t() @ J\n",
                "        A = JtJ + l * torch.diag(JtJ)\n",
                "        delta = torch.linalg.solve(A , J.t() @ residuals)\n",
                "        beta.sub_(delta)\n",
                "        if k > 1:\n",
                "            if loss[k] < loss[k-1]:\n",
                "                l /= 5\n",
                "            else:\n",
                "                l *= 2\n",
                "                beta.add_(delta)\n",
                "            if torch.abs(loss[k]-loss[k-1]) / loss[k] < 1e-2 :\n",
                "                break\n",
                "\n",
                "    residuals = model(beta) - ydata \n",
                "    loss.append(torch.mean(torch.square(residuals)))     \n",
                "    cov = A.inverse() * loss[-1]\n",
                "    return beta, cov, loss\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fitting a PSF aberrations\n",
                "\n",
                "from scipy.optimize import least_squares\n",
                "\n",
                "# We first generate some data\n",
                "shape = [64,64,32] \n",
                "pixel_size = [100,100,300] \n",
                "wavelength = 500\n",
                "NA = 1\n",
                "medium_refractive_index = 1.3\n",
                "aberrations = np.array([0,0,0,0.1,1])\n",
                "\n",
                "otf,psf = generate_otf3d(shape,pixel_size,wavelength,NA,medium_refractive_index,aberrations)\n",
                "plt.imshow(np.fft.fftshift(psf[:,0,:]))\n",
                "\n",
                "x0 = np.array([0,0,0,0.1,0,1,0,0])\n",
                "grid = generate_otf3d_grid(shape,pixel_size)\n",
                "model = lambda c: (generate_otf3d(shape,pixel_size,wavelength,NA,medium_refractive_index,c)[1] - psf).ravel()\n",
                "res = least_squares(model, x0)\n",
                "res.x"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = np.array([-1,2,3,4])\n",
                "#print(np.clip(x,0,None))\n",
                "print(np.maximum(x,0))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import numpy as np\n",
                "from scipy.optimize import least_squares\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "class PSFGenerator:\n",
                "    '''\n",
                "    Scalar point spread function generator\n",
                "\n",
                "    This class enable to precompute some arrays in order to accelerate\n",
                "    evaluation when fitting for example.\n",
                "    \n",
                "    '''\n",
                "    def __init__(self, shape, pixel_size, wavelength, NA, medium_refractive_index,mode='wf'):\n",
                "        self.shape = np.array(shape)\n",
                "        self.pixel_size = pixel_size\n",
                "        self.wavelength = wavelength\n",
                "        self.NA = NA\n",
                "        self.medium_refractive_index = medium_refractive_index\n",
                "        self.aberration_names = ('[1] Tilt-X','[2] Tilt-Y','[3] Focus','[4] Astigmatism & Defocus','[5] Astigmatism & Defocus','[6] Coma & Tilt','[7] Coma & Tilt','[8] Spherical & Defocus','[9]','[10]','[11]','[12]','[13]','[14]','[15]')\n",
                "        self.mode = mode\n",
                "        f = [np.fft.fftfreq(n, pixel_size[k]) for k, n in enumerate(shape)]\n",
                "        ez = np.concatenate((np.arange(0,shape[2]//2), np.arange((-shape[2])//2,0))) * pixel_size[2]\n",
                "        [kx,ky,kz] = np.meshgrid(*f)\n",
                "        z = np.meshgrid(f[0],f[1],ez)[2]\n",
                "        d2 = np.square(kx) + np.square(ky)\n",
                "        rho = np.sqrt(d2) * wavelength / NA\n",
                "        # pupille with correction for high NA\n",
                "        corr =  np.power(np.maximum( 1 - d2 / (medium_refractive_index / wavelength)**2, 1e-3), -0.25)\n",
                "        self.P = np.where(rho <= 1.0, 1.0, 0.0) * corr\n",
                "        # defocus term on a spherical cap\n",
                "        self.defocus = z * np.sqrt(np.clip((medium_refractive_index / wavelength)**2 - d2, 0, None))\n",
                "        self.dist = np.sqrt(d2 + np.square(kz))\n",
                "        # 2D array stored to accelerate aberration computation\n",
                "        [kx,ky] = np.meshgrid(f[0],f[1])\n",
                "        rho = np.sqrt(np.square(kx) + np.square(ky)) * wavelength / NA\n",
                "        theta = np.arctan2(ky, kx)\n",
                "        self.r = rho\n",
                "        self.r2 = np.square(rho)\n",
                "        self.r3 = np.power(rho,4.0)\n",
                "        self.r4 = np.power(rho,4.0)\n",
                "        self.c = np.cos(theta)\n",
                "        self.s = np.sin(theta)\n",
                "        self.c2 = np.cos(2*theta)\n",
                "        self.s2 = np.sin(2*theta)\n",
                "        self.c3 = np.cos(3*theta)\n",
                "        self.s3 = np.sin(3*theta)\n",
                "\n",
                "    def fft_sphere(self, alpha, l, type):\n",
                "        '''\n",
                "        Fourier transform of uniform sphere or shell in 2D or 3D\n",
                "        Parameters\n",
                "        ----------\n",
                "        alpha : frequency\n",
                "        l : radius of the sphere\n",
                "        type : type uniform3, shell3, uniform2, shell2\n",
                "        Result\n",
                "        ------\n",
                "        fft of the sphere or shell\n",
                "        Note\n",
                "        ----\n",
                "        Useful for computing image of beads, pinhole image, etc\n",
                "        https://doi.org/10.1093/qmath/12.1.165\n",
                "        '''\n",
                "        x = 2 * math.pi * alpha * l\n",
                "        if type == \"uniform3\":\n",
                "            return 3 * (np.sin(x) / np.power(x,3.0) - np.cos(x) / np.power(x,2.0))\n",
                "        elif type == \"uniform2\":\n",
                "            return 2 * np.special.j1(x) / x\n",
                "        elif type == \"shell2\": \n",
                "            return 2 * np.special.j1(x)\n",
                "        elif type == \"shell3\":\n",
                "            return np.sin(x) / x\n",
                "\n",
                "    def generate_psf(self,aberrations=None,mode='widefield',pinhole=1.0):\n",
                "        '''\n",
                "        Generate the point spread function\n",
                "        '''\n",
                "        if aberrations is not None:\n",
                "            phase = self.defocus + self.zernike_polynomial(aberrations)\n",
                "            \n",
                "        if mode == 'widefield':\n",
                "            psf = np.square(np.abs(np.fft.fft2( self.P * np.exp(2j * math.pi * phase), axes=[0,1])))\n",
                "            psf = psf / psf.sum()\n",
                "        if mode == 'confocal':\n",
                "            # assuming same detection and excitation psf\n",
                "            psf = np.square(np.abs(np.fft.fft2( self.P * np.exp(2j * math.pi * phase), axes=[0,1])))\n",
                "            D = self.fft_sphere(self.rho, pinhole, \"uniform2\")\n",
                "            psf = psf * np.real(np.fft.ifftn(np.fft(np.fft.fftn(psf) * D)))\n",
                "            psf = psf / psf.sum()\n",
                "        elif mode == 'ism': \n",
                "            # assuming same detection and excitation psf\n",
                "            psf = np.power(np.abs(np.fft.fft2( self.P * np.exp(2j * math.pi * phase), axes=[0,1])), 4)\n",
                "            psf = np.power(psf, 2.0)\n",
                "            psf = psf / psf.sum()\n",
                "        return psf\n",
                "\n",
                "    def generate_otf(self,aberrations=None, mode='widefield'):\n",
                "        '''\n",
                "        Generate the optical transfer function\n",
                "        '''\n",
                "        psf = self.generate_psf(aberrations, mode)\n",
                "        otf = np.fft.fftn(psf)\n",
                "        return otf\n",
                "\n",
                "    def generate_bead(self, params, mode='widefield'):\n",
                "        '''\n",
                "        Generate the image of a bead\n",
                "        params : [background, amplitude, sigma, 15 zernike coefficients ]\n",
                "        '''\n",
                "        otf = self.generate_otf(params[3:], mode)\n",
                "        sigma = 1000*params[2]   \n",
                "        if abs(sigma) > 1e-6 :\n",
                "            obj = self.fft_sphere(self.dist, sigma, 'shell3d')            \n",
                "            bead = np.fft.fftshift(np.real(np.fft.ifftn(otf * obj)))\n",
                "        else:\n",
                "            bead = np.fft.fftshift(np.real(np.fft.ifftn(otf)))\n",
                "\n",
                "        bead = bead / np.max(bead)\n",
                "        bead = params[0] + params[1]**2 * bead\n",
                "        bead = np.clip(bead,0,2*params[1])\n",
                "        return bead\n",
                "        \n",
                "    def zernike_polynomial(self,coefficients):\n",
                "        '''\n",
                "        Zernike polynomials\n",
                "        Parameter\n",
                "        ---------\n",
                "        coefficient: 15 or less Zernike coefficients\n",
                "        Note\n",
                "        ----\n",
                "        http://wyant.optics.arizona.edu/zernikes/Zernikes.pdf\n",
                "        \n",
                "        '''\n",
                "        if coefficients.shape[0] < 15:\n",
                "            coefficients = np.pad(coefficients,(0,15-coefficients.shape[0]))\n",
                "        P = np.zeros(self.r.shape)\n",
                "        P = P + coefficients[0] * self.r * self.c\n",
                "        P = P + coefficients[1] * self.r * self.s\n",
                "        P = P + coefficients[2] * (2. * self.r2 - 1.)\n",
                "        P = P + coefficients[3] * self.r2 * self.c2\n",
                "        P = P + coefficients[4] * self.r2 * self.s2\n",
                "        P = P + coefficients[5] * (3. * self.r2 - 2.) * self.r * self.c\n",
                "        P = P + coefficients[6] * (3. * self.r2 - 2.) * self.r * self.s\n",
                "        P = P + coefficients[7] * (6. * self.r4 - 6. * self.r2 + 1.)\n",
                "        P = P + coefficients[8] * self.r3 * self.c3\n",
                "        P = P + coefficients[9] * self.r3 * self.s3\n",
                "        P = P + coefficients[10] * (4. * self.r3 - 3) * self.r2 * self.c2\n",
                "        P = P + coefficients[11] * (4. * self.r3 - 3) * self.r2 * self.s2\n",
                "        P = P + coefficients[12] * (10. * self.r4 - 12. * self.r2 + 3.) * self.r  * self.c\n",
                "        P = P + coefficients[13] * (10. * self.r4 - 12. * self.r2 + 3.) * self.r  * self.s\n",
                "        P = P + coefficients[14] * ((20. * self.r4 - 30 * self.r2 + 12.)  * self.r2 - 1.0)\n",
                "        P = np.where(self.r < 1.0, P, 0)\n",
                "        return np.moveaxis(np.broadcast_to(P, self.shape[[2,0,1]]), 0, -1)\n",
                "    \n",
                "    def fit_bead(self,bead, x0=None):\n",
                "        '''\n",
                "        Fit a bead estimating the contrast, sigma and aberrations\n",
                "        Parameters\n",
                "        ---------\n",
                "        bead : a np.array with a bead at the center\n",
                "        '''\n",
                "        a = np.max(bead)\n",
                "        b = np.min(bead)\n",
                "        bead = (bead - b) / (a - b)\n",
                "        #model = lambda x: (self.generate_bead(x) - bead).ravel()\n",
                "        model = lambda x: (np.sqrt(np.abs(self.generate_bead(x))) - np.sqrt(bead)).ravel()\n",
                "        if x0 is None:\n",
                "            x0 = np.array([0,1,0.1,0,0,0,0,0.1,0,0,0,0,0,0,0,0,0,0])\n",
                "        res = least_squares(model, x0)\n",
                "        background = res.x[0]\n",
                "        amplitude = res.x[1]\n",
                "        sigma = res.x[2]\n",
                "        aberrations = res.x[3:]\n",
                "        print(f'background:{background} amplitude:{amplitude} sigma:{sigma}')\n",
                "        return sigma, aberrations, res.x\n",
                "    \n",
                "    \n",
                "shape = [64,64,32]\n",
                "pixel_size = [100,100,100]\n",
                "wavelength = 500\n",
                "NA = 1.4\n",
                "medium_refractive_index = 1.4\n",
                "psfgen = PSFGenerator(shape, pixel_size, wavelength, NA, medium_refractive_index)\n",
                "xstar = np.concatenate(  (np.array([0,1,0.01]), 0.001 * np.random.randn(15))  )\n",
                "bead = psfgen.generate_bead(xstar)\n",
                "plt.imshow(np.log(1e-6+np.max(bead,axis=0)))\n",
                "#sigma,aberrations,x = psfgen.fit_bead(bead)\n",
                "#fig, ax = plt.subplots(1,2)\n",
                "#ax[1].imshow(np.max(bead,axis=2))\n",
                "#ax[0].barh(psfgen.aberration_names, aberrations)\n",
                "#ax[0].invert_yaxis()\n",
                "#ax[0].set_box_aspect(1)\n",
                "#ax[0].set_title('Zernike coefficients')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tifffile\n",
                "from skimage.transform import rescale\n",
                "\n",
                "def analyze_bead(filename,channel):\n",
                "    wavelength = [510,570,670]\n",
                "    bead = tifffile.imread(filename)\n",
                "    bead = np.moveaxis(bead[:,channel,:,:],0,-1)\n",
                "    bead = bead[:,:,9:33]\n",
                "    bead = rescale(bead, zoom)\n",
                "    bead = np.pad(bead-np.median(bead),((8,8),(8,8),(0,0)))\n",
                "    pixel_size = np.array([65.4762,65.4762,100])/zoom\n",
                "    NA = 1.4\n",
                "    medium_refractive_index = 1.335\n",
                "    psfgen = PSFGenerator(bead.shape, pixel_size, wavelength[channel], NA, medium_refractive_index,'ism')\n",
                "    x = np.array([0,1.0,0.1,0,0,0,0.1,0.1,0,0,-0.1])\n",
                "    s,a,x = psfgen.fit_bead(bead, x)\n",
                "    s,a,x = psfgen.fit_bead(bead, np.concatenate((x,0.01 * np.random.randn(18-x.shape[0]))))\n",
                "    # make a figure\n",
                "    fig, ax = plt.subplots(1, 5, figsize=(15,30))\n",
                "    ax[0].barh(psfgen.aberration_names[:a.shape[0]], a)\n",
                "    ax[0].invert_yaxis()\n",
                "    ax[0].set_box_aspect(1)\n",
                "    ax[0].set_title(f'Zernike coefficients @ {wavelength[channel]} nm')\n",
                "    ax[1].imshow(np.max(bead, axis=2))\n",
                "    ax[1].axis('off')\n",
                "    ax[1].set_title('data XY')\n",
                "    ax[2].imshow(np.max(bead, axis=0))\n",
                "    ax[2].axis('off')\n",
                "    ax[2].set_title('data XZ')\n",
                "    ax[3].imshow(np.max(psfgen.generate_bead(x), axis=0))\n",
                "    ax[3].axis('off')\n",
                "    ax[3].set_title('estimate XZ')\n",
                "    residuals = psfgen.generate_bead(x) - (bead - np.min(bead)) / (np.max(bead) - np.min(bead))\n",
                "    ax[4].imshow(np.max(np.abs(residuals), axis=0))\n",
                "    ax[4].axis('off')\n",
                "    ax[4].set_title(f'RMS:{100*np.sqrt(np.mean(np.square(residuals))):.3f} %')\n",
                "\n",
                "\n",
                "analyze_bead('C:\\\\Users\\\\jeromeb\\\\Documents\\\\work\\\\data\\\\buzz\\\\Beads_test_All_collors_Sulfochamber_RT_merged-crop.tif',1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "analyze_bead('C:\\\\Users\\\\jeromeb\\\\Documents\\\\work\\\\data\\\\buzz\\\\75degree2.tif',0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = np.ones((1,5))\n",
                "print(x)\n",
                "print(x.shape)\n",
                "y = np.tile(x,[4,1])\n",
                "print(y)\n",
                "for i in range(4):\n",
                "    y[:,i] = y[:,i] + i\n",
                "y"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.13 ('imaging')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "af652b78da32f40db052c887d212218f2b9dfc5bd9e07e878617985773e27cfb"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
