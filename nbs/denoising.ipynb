{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Denoising\n",
    "\n",
    "Acquired images are corrupted by noise. Noise are random variations that are due\n",
    "the intrinsic quantic nature of light and thermal agitation of electrons in the \n",
    "circuits. \n",
    "\n",
    "Denoising is a fundamental problem in image processing as it requires to\n",
    "model the nature of the image itself and therefore provided a good experimental\n",
    "validation. Over the years many approaches have been proposed for\n",
    "denoising images based on various assumption on the image.\n",
    "\n",
    "Experimental validation:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "T. Plotz and S. Roth, ‘Benchmarking Denoising Algorithms With Real Photographs’, presented at the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 1586–1595. Available: https://openaccess.thecvf.com/content_cvpr_2017/html/Plotz_Benchmarking_Denoising_Algorithms_CVPR_2017_paper.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM3D\n",
    "\n",
    "BM3D is one of the most performant approach for method not actively based on \n",
    "learning.\n",
    "\n",
    "Y. Mäkinen, L. Azzari, A. Foi, 2020, \"Collaborative Filtering of Correlated Noise: Exact Transform-Domain Variance for Improved Shrinkage and Patch Matching\", in IEEE Transactions on Image Processing, vol. 29, pp. 8339-8354.\n",
    "\n",
    "We can install BM3D from pip\n",
    "```\n",
    "    pip install bm3d\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell is your are developing the code locally\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import site\n",
    "site.addsitedir('../') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the denoising method on a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from bm3d import bm3d\n",
    "import skimage\n",
    "\n",
    "noise_std = 20\n",
    "im = skimage.data.astronaut()[:,:,0]\n",
    "noise = np.random.normal(0, noise_std, im.shape)\n",
    "noisy = im.copy() + noise\n",
    "denoised = bm3d(noisy, noise_std)\n",
    "\n",
    "# display the result with quality metric\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "ax[0].imshow(im, cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "ax[1].imshow(noisy, cmap='gray')\n",
    "ax[1].set_title(f'Noisy image {skimage.metrics.peak_signal_noise_ratio(im, noisy, data_range=255):.2f}dB')\n",
    "ax[2].imshow(denoised, cmap='gray')\n",
    "ax[2].set_title(f'Denoised image {skimage.metrics.peak_signal_noise_ratio(im, denoised, data_range=255):.2f}dB')\n",
    "for a in ax:\n",
    "    a.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mug import denoising\n",
    "result_bm3d = denoising.benchmark(bm3d, '../data/Set12/*.png', blind=False, noise_levels=range(5,40,5))\n",
    "result_bm3d.pivot_table('psnr','noise level','image name').plot()\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('Set12 Benchmark for BM3D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DnCNN\n",
    "In DnCNN the task is set to predict the the residual image between the noisy and\n",
    "the noise free image. The network is composed of a deep (17 stage) sequence of \n",
    "blocks composed of convolution, batch normalization and RELU. The training is \n",
    "done by cropping 50x50 patches of images.\n",
    "\n",
    "A supervised with known noise level and a blind version can be trained.\n",
    "\n",
    "Zhang, Kai, et al. \"Beyond a gaussian denoiser: Residual learning of deep cnn for \n",
    "image denoising.\" IEEE transactions on image processing 26.7 (2017): 3142-3155."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dncnn_model = denoising.DnCNN()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dncnn_model.to(device)\n",
    "train_dataset = denoising.ImageFolderDataset('../data/Set12/*', denoising.DnCNNAugmenter([64,64], [10,30]),1000)\n",
    "train_dl = DataLoader(train_dataset, batch_size=10)\n",
    "optimizer = optim.AdamW(dncnn_model.parameters(), lr=1e-6)\n",
    "train_dl = DataLoader(train_dataset, batch_size=12)\n",
    "loss_fn = nn.MSELoss()\n",
    "lropt, h = lr_finder(dncnn_model,optimizer,loss_fn,train_dl,device,1e-6,10)\n",
    "plt.loglog(h['learning rate'],h['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mug import denoising\n",
    "from mug import utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#dncnn_model = denoising.DnCNN()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dncnn_model.to(device)\n",
    "train_dataset = denoising.ImageFolderDataset('../data/Set12/*', denoising.DnCNNAugmenter([64,64], [10,30]))\n",
    "valid_dataset = denoising.ImageFolderDataset('../data/Set12/*', denoising.DnCNNAugmenter([64,64], [10,30]))\n",
    "train_dl = DataLoader(train_dataset, batch_size=4)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=4)\n",
    "num_epochs = 100\n",
    "optimizer = optim.AdamW(dncnn_model.parameters(), lr = 3e-4)\n",
    "#lropt, h0 = denoising.lr_finder(dncnn_model,optimizer,loss_fn,train_dl,device,1e-6,10)\n",
    "#print(f'Optimal learning rate {lropt}')\n",
    "optimizer = optim.AdamW(dncnn_model.parameters(), lr = lropt)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_dl), epochs=num_epochs)\n",
    "loss_fn = nn.MSELoss()\n",
    "history = utils.train_network(dncnn_model,optimizer,loss_fn,train_dl,valid_dl,num_epochs,device)\n",
    "plt.plot(history['train_epoch'],history['train_loss'])\n",
    "plt.plot(history['valid_epoch'],history['valid_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mug import denoising\n",
    "dncnn = denoising.DnCNNDenoiser(dncnn_model)\n",
    "result_dncnn = denoising.benchmark(dncnn, '../data/Set12/*.png', blind=True, noise_levels=range(5,40,5))\n",
    "result_dncnn.pivot_table('psnr','noise level','image name').plot()\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('Set12 Benchmark for DnCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bm3d.pivot_table('psnr','noise level','image name').agg('mean',axis=1).plot()\n",
    "result_dncnn.pivot_table('psnr','noise level','image name').agg('mean',axis=1).plot()\n",
    "plt.legend(['bm3d','dncnn'])\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('Average Set12 Benchmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import numpy as np\n",
    "from mug import denoising\n",
    "\n",
    "def psnr(x, y, vmax = 255):\n",
    "    \"\"\"Peak signal to noise ratio quality metric\"\"\"\n",
    "    import math\n",
    "    return 10 * math.log10(vmax * vmax / np.mean(np.square(x - y)))\n",
    "    \n",
    "noise_std = 10\n",
    "im = skimage.data.astronaut()[:,:,0]\n",
    "noise = np.random.normal(0, noise_std, im.shape)\n",
    "noisy = im.copy() + noise\n",
    "\n",
    "dncnn = denoising.DnCNNDenoiser(dncnn_model)\n",
    "denoised = dncnn(noisy)\n",
    "\n",
    "# display the result with quality metric\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "ax[0].imshow(im, cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "ax[1].imshow(noisy, cmap='gray')\n",
    "ax[1].set_title(f'Noisy image {psnr(noisy, im):.2f}dB')\n",
    "ax[2].imshow(denoised, cmap='gray')\n",
    "ax[2].set_title(f'Denoised image {psnr(denoised, im):.2f}dB')\n",
    "for a in ax:\n",
    "    a.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drunet_model = denoising.DRUNET()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "drunet_model.to(device)\n",
    "train_dataset = denoising.ImageFolderDataset('../data/Set12/*', denoising.DRUNETAugmenter([64,64], [10,30]))\n",
    "valid_dataset = denoising.ImageFolderDataset('../data/Set12/*', denoising.DRUNETAugmenter([64,64], [10,30]))\n",
    "train_dl = DataLoader(train_dataset, batch_size=2)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=2)\n",
    "num_epochs = 100\n",
    "optimizer = optim.AdamW(drunet_model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_dl), epochs=num_epochs)\n",
    "loss_fn = nn.MSELoss()\n",
    "history = utils.train_network(drunet_model,optimizer,loss_fn,train_dl,valid_dl,num_epochs,device)\n",
    "plt.plot(history['train_epoch'],history['train_loss'])\n",
    "plt.plot(history['valid_epoch'],history['valid_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_dataset[0]\n",
    "with torch.no_grad():\n",
    "    yhat = drunet_model(x.reshape([1,*x.shape]))\n",
    "fig, ax = plt.subplots(1,4)\n",
    "ax[0].imshow(x[0].cpu().numpy().squeeze())\n",
    "ax[1].imshow(x[1].cpu().numpy().squeeze())\n",
    "ax[2].imshow(y.cpu().numpy().squeeze())\n",
    "ax[3].imshow(yhat.cpu().numpy().squeeze())\n",
    "print(x[1].mean(),(x[0]-y).mean(),(yhat-y).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mug import denoising\n",
    "drunet = denoising.DRUNETDenoiser(drunet_model)\n",
    "result_drunet = denoising.benchmark(drunet, '../data/Set12/*.png', blind=False, noise_levels=range(5,40,2))\n",
    "result_drunet.pivot_table('psnr','noise level','image name').plot()\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('Set12 Benchmark for DRUNET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "drunet = denoising.DRUNETDenoiser(model)\n",
    "im = skimage.data.astronaut()[:,:,0].astype(float)\n",
    "noisy = im + np.random.normal(0,10, size=im.shape)\n",
    "estimate = drunet(im,10.)\n",
    "plt.subplot(121).imshow(noisy,cmap='gray')\n",
    "plt.subplot(122).imshow(estimate,cmap='gray')\n",
    "psnr = peak_signal_noise_ratio(im, estimate, data_range=255)\n",
    "plt.title(f'PSNR {psnr:.2f}dB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bm3d.pivot_table('psnr','noise level','image name').agg('mean',axis=1).plot()\n",
    "result_dncnn.pivot_table('psnr','noise level','image name').agg('mean',axis=1).plot()\n",
    "result_drunet.pivot_table('psnr','noise level','image name').agg('mean',axis=1).plot()\n",
    "plt.legend(['bm3d','dncnn','drunet'])\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('Average Set12 Benchmark for DnCNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson - Gaussian noise \n",
    "Poisson-Gaussian noise model is able to capture both the shot noise and the \n",
    "readout noise of the cameras.\n",
    "\n",
    "For denoising image corrupted by a Poisson-Gaussian noise, a variance\n",
    "stabilization step allows to convert the signal dependend noise to a signal\n",
    "independent noise of variance 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = skimage.data.astronaut()[:,:,0].astype(float)\n",
    "im = skimage.filters.gaussian(im,4)\n",
    "gain = 1\n",
    "offset = 10\n",
    "sigma = 1\n",
    "noisy = gain * np.random.poisson(im) + offset + np.random.normal(0,sigma,size=im.shape)\n",
    "gat = denoising.generalized_anscombe_transform(gain, offset, sigma)\n",
    "# gat.calibrate(noisy)\n",
    "variance_stabilized = gat(noisy)\n",
    "x0, y0 = denoising.compute_local_statistics(noisy)\n",
    "x1, y1 = denoising.compute_local_statistics(variance_stabilized)\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "ax[0].scatter(x0.flatten()[::50], y0.flatten()[::50], alpha=0.1)\n",
    "ax[0].set_title('Before stabilization')\n",
    "ax[0].set_xlabel('Mean intensity')\n",
    "ax[0].set_ylabel('Noise variance')\n",
    "ax[1].scatter(x1.flatten()[::50], y1.flatten()[::50], alpha=0.1)\n",
    "ax[1].set_title('After stabilization')\n",
    "ax[1].set_xlabel('Mean intensity')\n",
    "ax[1].set_ylabel('Noise variance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('imaging')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af652b78da32f40db052c887d212218f2b9dfc5bd9e07e878617985773e27cfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
